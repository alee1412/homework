{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cheat Sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to import files\n",
    "filepath_pd = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check a csv file\n",
    "file = input(\"Question?\")\n",
    "found = False\n",
    "with open(filepath, newline=\"\") as csvfile:\n",
    "    csvreader = csv.reader(filepath, delimiter=\",\")\n",
    "    for row in csvreader:\n",
    "        if(row[0] == video):\n",
    "            print(row[0] + \"text\" + row[1])\n",
    "            found = True\n",
    "    #If there is nothing in that file found\n",
    "    if found == False:\n",
    "        print(\"Nothing there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary part 1\n",
    "\n",
    "new_dataframe = pd.Series([\"item\", \"item\", \"item\", \"item\"])\n",
    "\n",
    "#converting to a dictionary\n",
    "new_dictionary = [{\"Dictionary1\": \"item\", \"Dictionary2\": \"item\"},\n",
    "                 {\"Dictionary1\": \"item\", \"Dictionary2\": \"item\"}]\n",
    "new_dictionary_dataframe = pd.DataFrame(new_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary part 2\n",
    "\n",
    "new_dataframe = pd.DataFrame({\n",
    "    \"Column 1\": [\"item1\", \"item2\", \"item3\"],\n",
    "    \"Column 2\": [\"item1\", \"item2\", \"item3\"],\n",
    "    \"Column 3\": [\"item1\", \"item2\", \"item3\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Describe to get Count, Mean, STD, Min, 25%, 50%, 75%, Max\n",
    "datafile_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Referencing multiple column(s)\n",
    "datafile_pd[\"Column1\"].head()\n",
    "datafile_pd[\"Column1\", \"Column2\"]\n",
    "\n",
    "#Only show multiple columns\n",
    "data_file_pd[[\"Column1\", \"Column2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding sum or mean, or unique values\n",
    "average = data_pd[\"column1\"].mean()\n",
    "sum = data_pd[\"column1\"].sum()\n",
    "unique_values = data_pd[\"column1\"].unique()\n",
    "unique_value_count = data_pd[\"column1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing a calculation and adding a new column\n",
    "calculation = data_pd[\"Column1\"]/1000\n",
    "data_pd[\"New Column\"] = calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the names of all the columns\n",
    "data_pd.columns\n",
    "\n",
    "#Reorganizing the columns\n",
    "organized_pd = new_pd[[\"Item1\", \"Item2\", \"Item3\", \"Item4\"]]\n",
    "\n",
    "#Renaming columns\n",
    "renamed_pd = new_pd.rename(columns={\"Item1\":\"Item 1\"})\n",
    "\n",
    "#Setting a new index on a column\n",
    "new_index = data_pd.set_index(\"Column 1\")\n",
    "\n",
    "#Delete a column\n",
    "del data_pd[\"Column8\"]\n",
    "\n",
    "#Identify incomplete rows\n",
    "data_pd.count()\n",
    "\n",
    "#Dropping all rows with missing information\n",
    "data_pd = data_pd.dropna(how='any')\n",
    "\n",
    "#Figuring out data types\n",
    "data_pd.dtypes\n",
    "\n",
    "#Changing data types to numeric\n",
    "data_pd[\"Column1\"] = pd.to_numeric(data_pd[\"Column1\"])\n",
    "\n",
    "#Verifying data type\n",
    "data_pd[\"Column1\"].dtype\n",
    "\n",
    "#Combining columns together\n",
    "data_pd[\"Column1\"] = data_pd[\"Column1\"].replace({\n",
    "    \"Row 1\": \"Row 2\", \"Row 3\": \"Row 2\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loc and iLoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using loc and iloc\n",
    "\n",
    "#Locates loc within the index\n",
    "loc_item = data_pd.loc[\"Index\", \"Column1\"]\n",
    "\n",
    "#Use loc to narrow down a dataframe\n",
    "loc_item = data_pd.loc[[\"Index1\", \"Index2\", \"Index3\"], [\"Column1\", \"Column2\"]]\n",
    "\n",
    "#Use loc to only select certain rows for columns\n",
    "df.loc[:, [\"Column1\", \"Column2\"]]\n",
    "\n",
    "#Use Loc to find specific values\n",
    "specfic_value = data_pd.loc[data_pd[\"Column1\"] == \"Specific Value\", :]\n",
    "#for 2\n",
    "specific_value = data_pd.loc[(data_pd[\"Column1\"] == \"Specific Value\") | (data_pd[\"Column1\"] == \"Specific Value 2\"), :]\n",
    "\n",
    "#iLoc uses [Row, Column] to find \n",
    "iloc_item = data_pd.iloc[1, 2]\n",
    "\n",
    "#iloc will not find duplicates in a numeric index, [rows, columns]\n",
    "iloc_item = data_pd.iloc[0:4, 0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](http://www.datasciencemadesimple.com/wp-content/uploads/2017/09/join-or-merge-in-python-pandas-1.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Tables\n",
    "merged_table = pd.merge(dataframe1, dataframe2, on=\"same_column\", how=\"outer\")\n",
    "\n",
    "#Setting a suffix\n",
    "merged_table = pd.merge(dataframe1, dataframe2, on=\"same_column\", suffixes=(\"_Suffix DF1\", \"_Suffix DF2\") how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating bins holding data\n",
    "bins = [Num1, Num2, Num3, Num4, Num5]\n",
    "\n",
    "#Creating names for bins\n",
    "bin_names = [\"Name1\", \"Name2\", \"Name3\", \"Name4\"]\n",
    "\n",
    "#Making the DataFrame\n",
    "data_frame[\"Index Column\"] = pd.cut(data_frame[\"Column1\"], bins, labels=bin_names)\n",
    "\n",
    "data_frame = data_frame.groupby(\"Index Column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging 4 dataframes\n",
    "DF1 = pd.read_csv(\"Folder/File name.csv\")\n",
    "DF2 = pd.read_csv(\"Folder/File name.csv\")\n",
    "DF3 = pd.read_csv(\"Folder/File name.csv\")\n",
    "DF4 = pd.read_csv(\"Folder/File name.csv\")\n",
    "\n",
    "combined_df = pd.merge(DF1, DF2, how=\"outer\", on=\"Column1\")\n",
    "combined_df = pd.merge(combined_df, DF3, how=\"outer\", on=\"Column1\")\n",
    "combined_df = pd.merge(combined_df, DF4, how=\"outer\", on=\"Column1\")\n",
    "\n",
    "#Replace all NaN Values with 0\n",
    "combined_df = combined_df.fillna(0)\n",
    "\n",
    "#To create a new column with all the values added up\n",
    "combined_df[\"New Column 1\"] = combined_df[\"Column1\"] + combined_df[\"Column2\"]\n",
    "combined_df[\"New Column 2\"] = combined_df[\"Column3\"] + combined_df[\"Column4\"]\n",
    "combined_df[\"New Column 3\"] = combined_df[\"Column5\"] + combined_df[\"Column6\"]\n",
    "\n",
    "#Finding specific items with values over certain amounts\n",
    "locating_stuff = combined_df.loc[(combined_df[\"New Column 1\"] >= 100)&\n",
    "                                (combined_df[\"New Column 2\"] > 0) &\n",
    "                                (combined_df[\"New Column 3\"] > 0)]\n",
    "\n",
    "#Setting an index\n",
    "locating_stuff = locating_stuff.set_index(\"Column 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formatting for ${:} for money, {:,} puts a comma, {:.2f} is two decimal points\n",
    "data_frame[\"column1\"] = dataframe[\"column1\"].map(\"${:,.2f}\".format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MatplotLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list with a .1 step up from 0 to 10\n",
    "x_axis = np.arange(0, 10, 0.1)\n",
    "\n",
    "#Creating an exponential series of values\n",
    "e_x = [np.exp(x) for x in x_axis]\n",
    "\n",
    "#plotting a graph between two lists\n",
    "plt.plot(x_axis, e_x)\n",
    "\n",
    "#showing plot\n",
    "plt.show()\n",
    "\n",
    "#Labeling\n",
    "plt.xlabel(\"X Label\")\n",
    "plt.ylabel(\"Y Label\")\n",
    "plt.title(\"Title\")\n",
    "\n",
    "#Legend (For the best location, upper or lower)\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "#Naming the legend\n",
    "plt.legend(handles=[Line_1, Line_2], loc=\"best\")\n",
    "\n",
    "#Formatting\n",
    "graph_1, = plt.plot(x_axis, y_axis, marker='o', color='blue', linewidth=1, label=\"Line1\")\n",
    "\n",
    "#Setting x and y limits\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(0, 10)\n",
    "\n",
    "#Saving a figure\n",
    "plt.savefig(\"Folder/file name.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis = [num1, num2, num3]\n",
    "x_axis = np.arange(len(bar_x_amount))\n",
    "tick_locations = [value for value in x_axis]\n",
    "plt.xticks(tick_locations, [\"Name1\", \"Name2\", \"Name3\"])\n",
    "\n",
    "#Setting the x limits\n",
    "plt.xlim(-.75, len(x_axis)-0.25)\n",
    "\n",
    "#Setting the y limits\n",
    "plt.ylim(0, max(y_axis)+5000)\n",
    "\n",
    "#Labeling\n",
    "plt.xlabel(\"X Label\")\n",
    "plt.ylabel(\"Y Label\")\n",
    "plt.title(\"Title\")\n",
    "\n",
    "#Figure size\n",
    "plt.figure(figsize=(20,3))\n",
    "\n",
    "#Plotting the bar chart\n",
    "plt.bar(x_axis, y_axis, color='r', alpha=.5, align=\"center\")\n",
    "\n",
    "#From a CSV\n",
    "data = pd.read_csv(\"Folder/file name.csv\")\n",
    "\n",
    "x_axis = np.arange(len(data))\n",
    "tick_locations = [value for value in x_axis]\n",
    "plt.figure(figsize=(20,3))\n",
    "plt.bar(x_axis, data[\"ColumnY\"], color='b', alpha=.5, align='edge')\n",
    "plt.xticks(tick_locations, data[\"ColumnX\"], rotation='vertical')\n",
    "plt.xlim(-.25, len(x_axis))\n",
    "plt.ylim(0, max(data[\"ColumnY\"]) + 10)\n",
    "plt.xlabel(\"X Label\")\n",
    "plt.ylabel(\"Y Label\")\n",
    "plt.title(\"Title\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Folder/file name.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pie Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Name1\", \"Name2\", \"Name3\", \"Name4\"]\n",
    "values = [Num1, Num2, Num3, Num4]\n",
    "colors = [\"yellow\", \"red\", \"coral\", \"blue\"]\n",
    "\n",
    "#Exploding the first section \n",
    "explode = [.1, 0, 0, 0]\n",
    "\n",
    "plt.pie(values, explode=explode, label=labels, color=colors, \n",
    "       autopct=\"%1.1f%%\", shadow=True, startangle=140)\n",
    "\n",
    "#Making an equal axes pie\n",
    "plt.axis(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maximum x value for chart\n",
    "x_limit = 100\n",
    "\n",
    "#List of values \n",
    "x_axis = np.arange(0, x_limit, 1)\n",
    "\n",
    "#Creating a random array of data for the y value\n",
    "y_value = [random.random() for value in x_axis]\n",
    "\n",
    "#plotting a scatter plot\n",
    "plt.scatter(x_axis, y_value, marker=\"*\", facecolors=\"red\", edgecolors=\"black\",\n",
    "           s=x_axis, alpha=0.75)\n",
    "\n",
    "#Y Limits from 0 to 1\n",
    "plt.ylim(0,1)\n",
    "\n",
    "#X Limits from 0 to 100\n",
    "plt.xlim(0, x_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using MatplotLib to Chart a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From a CSV to make a bar chart\n",
    "data = pd.read_csv(\"Folder/file name.csv\")\n",
    "\n",
    "x_axis = np.arange(len(data))\n",
    "tick_locations = [value for value in x_axis]\n",
    "\n",
    "plt.figure(figsize=(20,3))\n",
    "plt.bar(x_axis, data[\"ColumnY\"], color='b', alpha=.5, align='edge')\n",
    "plt.xticks(tick_locations, data[\"ColumnX\"], rotation='vertical')\n",
    "\n",
    "plt.xlim(-.25, len(x_axis))\n",
    "plt.ylim(0, max(data[\"ColumnY\"]) + 10)\n",
    "\n",
    "plt.xlabel(\"X Label\")\n",
    "plt.ylabel(\"Y Label\")\n",
    "plt.title(\"Title\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Folder/file name.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pandas to Chart a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter a DataFrame to using two columns\n",
    "XandY = data[[\"XColumn\", \"YColumn\"]]\n",
    "\n",
    "#Setting the index to be \"XColumn\" to be used as labels\n",
    "XandY = XandY.set_index(\"XRow\")\n",
    "\n",
    "XandY.plot(kind=\"bar\", figsize=(20,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting mulitple columns \n",
    "multi_plot = data.plot(kind=\"bar\", figsize=(20,5))\n",
    "\n",
    "#PandasPlot.set_xticklabels() can be used to set the tick labels as well\n",
    "multi_plot.set_xticklabels(data[\"ColumnX\"], rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining 2 columns and using it to plot a chart\n",
    "Column1_data = data[\"Column1\"].value_counts()\n",
    "Column2_data = data[\"Column2\"].value_counts()\n",
    "\n",
    "#Filling in a dataset with 0 to have it run on the second column\n",
    "total_data = Column1_data.add(Column2_data, fill_value=0)\n",
    "\n",
    "#Removing rows with missing values\n",
    "total_data = total_data.loc[total_data[\"Column1\"] != \"NaN\"]\n",
    "\n",
    "#Replacing all NaN values with 0\n",
    "data = data.fillna(0)\n",
    "\n",
    "#Bar graph\n",
    "total_data.plot(kind=\"bar\", facecolor=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using groupby to make a bar chart\n",
    "X_Value = data.groupby(\"Column1\")\n",
    "Y_Value = X_Value[\"Column2\"].count()\n",
    "\n",
    "#Dropping a column that is within the group\n",
    "#Y_Value = Y_Value.drop(Y_Value.index[3])\n",
    "\n",
    "#Creating a chart\n",
    "chart = Y_Value.plot(kind=\"bar\")\n",
    "\n",
    "#Xlabel and Ylabel\n",
    "chart.set_xlabel(\"X Title\")\n",
    "chart.set_ylabel(\"Y Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a Scatter Chart\n",
    "data.plot(kind=\"scatter\", x=\"Column1\", y=\"Column2\", grid=True, figsize=(20,10), \n",
    "         title=\"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import requests\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grabbing info from a basic API\n",
    "url = \"https://api.spacexdata.com/v2/launchpads\"\n",
    "\n",
    "#Use this to make sure the URL works\n",
    "response = requests.get(url)\n",
    "\n",
    "response_json = response.json\n",
    "print(json.dumps(response, indent=4, sort_keys=True))\n",
    "\n",
    "#Getting a specific value\n",
    "print(response[\"cost_per_launch\"])\n",
    "\n",
    "#To find a value within a sub-dictionaries{} and sub-list[]\n",
    "payload_weight = response[\"payload_weights\"][0][\"kg\"]\n",
    "\n",
    "#To collect and print out multiple requests from a URL.json within a URL.json\n",
    "array = []\n",
    "\n",
    "for array in response_json['Category']:\n",
    "    grabbing_urls = requests.get(urls_in_array).json()\n",
    "    plugging_in_variable = grabbing_urls['data in url array']\n",
    "    array.append(solving_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing Inputs and Returning data from an API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import requests\n",
    "import json\n",
    "\n",
    "#grabbing url from API\n",
    "url = \"http://numbersapi.com/\"\n",
    "\n",
    "#Asking the question, note Date requires 2 numbers, everything else requires 1 number\n",
    "question = (\"What type of data would you like to search for? \"\n",
    "            \"[Trivia, Math, Date, or Year] \")\n",
    "kind_of_search = input(question)\n",
    "\n",
    "#Searching to return one of the question types\n",
    "if(kind_of_search.lower() == \"date\"):\n",
    "    \n",
    "    #Collect month\n",
    "    month = input(\"What Month are you searching for?\")\n",
    "    #Collect day\n",
    "    day = input(\"What Day are you searching for?\")\n",
    "    \n",
    "    #Make the API request to \"date\" API and convert response to JSON\n",
    "    response = requests.get(f\"{url}{month}/{day}/{kind_of_search.lower()}?json\").json()\n",
    "    \n",
    "    #Print the fact stored within the response\n",
    "    print(response[\"text\"])\n",
    "    \n",
    "#Otherwise, for all other responses with 1 answer\n",
    "else:\n",
    "    #Collect the 1 number to search for\n",
    "    number = input(\"What number would you like to search for? \")\n",
    "    \n",
    "    #Make the API request and convert response to JSON\n",
    "    response = requests.get(url + number + \"/\" + kind_of_search.lower()+ \"?json\").json()\n",
    "    \n",
    "    #Print the Response\n",
    "    print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import json\n",
    "import requests\n",
    "#Random not needed\n",
    "import random \n",
    "\n",
    "url = \"http://jsonplaceholder.typicode.com/posts/\"\n",
    "\n",
    "#creating an empty list to store responses\n",
    "response_json = []\n",
    "\n",
    "#Not needed, but creating a random index representing a user's choice of posts\n",
    "indices = random.sample(list(range(1,100)), 10)\n",
    "\n",
    "#Make a request for each index\n",
    "for x in range(len(indices)):\n",
    "    print(f\"Making request number: {x} for ID: {indices[x]}\")\n",
    "    \n",
    "    #Grabbing one of the posts\n",
    "    post_response = requests.get(url + str(indices[x]))\n",
    "    \n",
    "    #Add and save to the list\n",
    "    response_json.append(post_response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import requests\n",
    "from pprint import pprint\n",
    "#Create a py file for api_key\n",
    "from config import api_key\n",
    "\n",
    "url = \"https://api.nytimes.com/svc/search/v2/articlesearch.json?\"\n",
    "\n",
    "#Search for a word in an article\n",
    "query = \"granola\"\n",
    "\n",
    "#Build the URL\n",
    "query_url = url + \"api-key=\" + api_key + \"&q=\" + query\n",
    "\n",
    "#Requesting an article\n",
    "articles = requests.get(query_url).json()\n",
    "\n",
    "#The \"response\" property in articles contains the actual articles list comprehension.\n",
    "articles_list = [article for article in articles[\"response\"][\"docs\"]]\n",
    "\n",
    "#Print the web_url of each stored article\n",
    "for article in articles_list:\n",
    "    print(article[\"web_url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from config import api_key\n",
    "\n",
    "url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
    "city = \"London\"\n",
    "units = \"metric\"\n",
    "\n",
    "#Build query URL\n",
    "query_url = url + \"appid=\" + api_key + \"&q=\" + city + \"&units=\" + units\n",
    "\n",
    "#Get data\n",
    "weather_response = requests.get(query_url)\n",
    "weather_json = weather_response.json()\n",
    "\n",
    "#Get the temperature from the json Dump\n",
    "print(f\"The weather API responded with: {json.dumps(weather_json, indent=2)}.\")\n",
    "\n",
    "#If you want to run two requests, have to do one at a time\n",
    "units = [\"metric\", \"imperial\"]\n",
    "temperatures = []\n",
    "\n",
    "for unit in units:\n",
    "    query_url = url + \"appid=\" + api_key + \"&q=\" + city + \"&units=\" + unit\n",
    "    weather_response = requests.get(query_url)\n",
    "    weather_json = weather_response.json()\n",
    "    \n",
    "    temperature = weather_json[\"main\"][\"temp\"]\n",
    "    temperatures.append(temperature)\n",
    "\n",
    "#Run both responses\n",
    "print(f\"The temperature in Bujumbra is {temperatures[0]} C or {temperatures[1]} F.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting info from an API into a DataFrame and making a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import pandas as pd\n",
    "from config import api_key\n",
    "\n",
    "url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
    "units = \"metric\"\n",
    "\n",
    "# Build partial query URL\n",
    "query_url = f\"{url}appid={api_key}&units={units}&q=\"\n",
    "\n",
    "#Create a list for the loop\n",
    "cities = [\"Paris\", \"London\", \"Oslo\", \"Beijing\"]\n",
    "\n",
    "#set up a list to hold the responses\n",
    "lat = []\n",
    "temp = []\n",
    "\n",
    "#Loop the first list into the empty lists\n",
    "for city in cities:\n",
    "    response = requests.get(query_url + city).json()\n",
    "    lat.append(response['coord']['lat'])\n",
    "    temp.append(response['main']['temp'])\n",
    "    \n",
    "#Create the data frame from cities, lat, and temp\n",
    "weather_dict = {\"city\": cities,\n",
    "               \"lat\": lat,\n",
    "               \"temp\": temp}\n",
    "\n",
    "weather_data = pd.DataFrame(weather_dict)\n",
    "\n",
    "#Build a scatter plot\n",
    "plt.scatter(weather_data[\"lat\"], weather_data[\"temp\"], marker=\"o\")\n",
    "\n",
    "# Incorporate the other graph properties\n",
    "plt.title(\"Temperature in World Cities\")\n",
    "plt.ylabel(\"Temperature (Celsius)\")\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"Images/TemperatureInWorldCities.png\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exception Handling Using Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to access key that doesn't exist\n",
    "try:\n",
    "    line that doesn't work\n",
    "#error is the KeyERror in this case\n",
    "except KeyError:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
